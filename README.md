# Awesome-vLLMs-Strawberry
A collection of vLLMs papers, blogs, and projects, with a focus on vLLMs in Autonomous Driving and related reasoning techniques.

## Papers

### 2024

- [Hint-AD: Holistically Aligned Interpretability in End-to-End Autonomous Driving](https://arxiv.org/pdf/2409.06702)
    - [Code](https://air-discover.github.io/Hint-AD/) <font color=LightCoral>coming soon
    - [Datasets](https://air-discover.github.io/Hint-AD/) <font color=LightCoral>coming soon

- [MiniDrive: More Efficient Vision-Language Models with Multi-Level 2D Features as Text Tokens for Autonomous Driving](https://arxiv.org/pdf/2409.07267)
    - [Code](https://github.com/EMZucas/minidrive) <font color=LightCoral>coming soon
    - [Drive-LM Datasets Tutorials](https://github.com/OpenDriveLab/DriveLM/tree/main/challenge)   
    - [CODA-LM Datasets Website](https://coda-dataset.github.io/coda-lm/)  
    - [CODA-LM Datasets Tutorials](https://github.com/DLUT-LYZ/CODA-LM)  

- [LMDrive: Closed-Loop End-to-End Driving with Large Language Models](https://arxiv.org/abs/2312.07488)
    - [Code](https://github.com/opendilab/LMDrive)
    - [LMDrive Datasets](https://openxlab.org.cn/datasets/deepcs233/LMDrive)

