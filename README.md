# Awesome-VLMs-Strawberry
A collection of VLMs papers, blogs, and projects, with a focus on VLMs in Autonomous Driving and related reasoning techniques.

## OpenAI Docs
- [https://platform.openai.com/docs/guides/reasoning](https://platform.openai.com/docs/guides/reasoning)
- <img src="https://github.com/user-attachments/assets/b165cb20-9202-4951-8783-6b2f7e0d6071" width="600px">

## Papers

### 2024

- [***HE-Drive: Human-Like End-to-End Driving with Vision Language Models [arxiv]***](https://arxiv.org/abs/2410.05051)
    - [*Code*](https://github.com/jmwang0117/HE-Drive) <img src="https://img.shields.io/github/stars/jmwang0117/HE-Drive.svg"/>
    - [*NuScenes-Datasets-Website*](https://www.nuscenes.org/nuscenes)
    - [*OpenScene-Datasets-Tutorials*](https://github.com/OpenDriveLab/OpenScene)

- [***Reason2Drive: Towards Interpretable and Chain-based Reasoning for Autonomous Driving [ECCV2024]***](https://arxiv.org/abs/2312.03661)
    - [*Code*](https://github.com/fudan-zvg/reason2drive) <img src="https://img.shields.io/github/stars/fudan-zvg/reason2drive.svg"/>
    - [*Datasets-GoogelDisk*](https://drive.google.com/file/d/16IInbGqEzg4UcNhTlxVA9tS6tOTi4wet/view?usp=sharing)
    - [*Datasets-BaiduDisk*](https://pan.baidu.com/s/1tzAuaB42RkguYM863zo6Jw?pwd=6g94)
    
- [***Hint-AD: Holistically Aligned Interpretability in End-to-End Autonomous Driving [CoRL 2024]***](https://arxiv.org/pdf/2409.06702)
    - [*Code*](https://air-discover.github.io/Hint-AD/) <span style="color: red;">*coming soon*</span>
    - [*Datasets*](https://air-discover.github.io/Hint-AD/) <span style="color: red;">*coming soon*</span>

- [***MiniDrive: More Efficient Vision-Language Models with Multi-Level 2D Features as Text Tokens for Autonomous Driving [arxiv]***](https://arxiv.org/pdf/2409.07267)
    - [*Code*](https://github.com/EMZucas/minidrive) <span style="color: red;">*coming soon*</span>
    - [*Drive-LM-Datasets-Tutorials*](https://github.com/OpenDriveLab/DriveLM/tree/main/challenge)   
    - [*CODA-LM-Datasets-Website*](https://coda-dataset.github.io/coda-lm/)  
    - [*CODA-LM-Datasets-Tutorials*](https://github.com/DLUT-LYZ/CODA-LM)  

- [***LMDrive: Closed-Loop End-to-End Driving with Large Language Models [CVPR2024]***](https://arxiv.org/abs/2312.07488)
    - [*Code*](https://github.com/opendilab/LMDrive) <img src="https://img.shields.io/github/stars/opendilab/LMDrive.svg"/>
    - [*LMDrive-Datasets*](https://openxlab.org.cn/datasets/deepcs233/LMDrive)

- [***CoDrivingLLM: Towards Interactive and Learnable Cooperative Driving Automation: a Large Language Model-Driven Decision-making Framework [arxiv]***](https://arxiv.org/pdf/2409.12812)  
    - [*Code*](https://github.com/FanGShiYuu/CoDrivingLLM) <img src="https://img.shields.io/github/stars/FanGShiYuu/CoDrivingLLM.svg"/>
    - *Dataset* ⚠️

### 2023

- [***DriveMLM: Aligning Multi-Modal Large Language Models with Behavioral Planning States for Autonomous Driving [arxiv]***](https://arxiv.org/pdf/2409.12812)
    - [*Code*](https://github.com/OpenGVLab/DriveMLM) <img src="https://img.shields.io/github/stars/OpenGVLab/DriveMLM.svg"/>
    - [*Dataset*](https://github.com/OpenGVLab/DriveMLM) <span style="color: red;">*coming soon*</span>